def svmTraining(training_set_filename, gamma_range, C_range, cv, probFlag, n_jobs, cs, svm_model_filename, grid_search_filename):
    import matplotlib as mpl
    mpl.use('Agg')  # Use Agg backend for matplotlib (no GUI)
    import matplotlib.pyplot as plt
    from sklearn import preprocessing
    from sklearn.svm import SVC
    from sklearn.model_selection import GridSearchCV
    import pickle
    import numpy as np
    from sklearn.metrics import cohen_kappa_score, make_scorer

    # This script selects the best model for an SVM using a brute-force grid search approach 
    # exploring the space generated by gamma and C. Once the best parameters are found, 
    # the script trains an SVM that can be applied for an online prediction.
    # The saved SVM model is a dict formed as follows:
    # 'svmModel': svm
    # 'normalizer': normalizer
    # 'feature_names': feature_names
    # 'target_names': target_names

    # Load the training set from the pickle file
    training_set = pickle.load(open(training_set_filename, 'rb'), encoding='latin1')
    feature_names = training_set['feature_names']
    target_names = training_set['target_names']
    Samples_train = training_set['data']
    Labels_train = training_set['target']

    # Normalize the training samples
    print("Normalization ...")
    normalizer = preprocessing.StandardScaler().fit(Samples_train)
    Samples_train_normalized = normalizer.transform(Samples_train)

    # Grid search to find the best hyperparameters
    print("Grid Search ...")
    tuned_parameters = [{'kernel': ['rbf'], 'C': C_range, 'gamma': gamma_range}]
    svm = SVC(decision_function_shape='ovr')
    grid = GridSearchCV(svm, tuned_parameters, cv=cv, scoring='accuracy', n_jobs=n_jobs, verbose=1)
    grid.fit(Samples_train_normalized, Labels_train)

    # Display the best parameters and their corresponding accuracy
    print("The best parameters are %s with an accuracy of %0.2f" % (grid.best_params_, grid.best_score_))

    # Plot the scores of the grid search
    scores = grid.cv_results_['mean_test_score']
    scores = np.array(scores).reshape(len(C_range), len(gamma_range))

    # Draw heatmap of the validation accuracy as a function of gamma and C
    plt.figure(figsize=(15, 15))
    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)
    plt.xlabel('gamma')
    plt.ylabel('cost')
    plt.colorbar()
    plt.xticks(np.arange(len(gamma_range)), ['%.3f' % a for a in gamma_range], rotation=45)
    plt.yticks(np.arange(len(C_range)), ['%.3f' % a for a in C_range])
    plt.title('Validation accuracy')

    # Train the SVM with the best parameters and the flag for estimating the probabilities
    svm = SVC(C=grid.best_params_['C'], kernel='rbf', gamma=grid.best_params_['gamma'], 
              probability=probFlag, decision_function_shape='ovr', cache_size=cs)
    svm.fit(Samples_train_normalized, Labels_train)

    # Save the trained SVM model to a pickle file
    svm_model = {'svmModel': svm, 'normalizer': normalizer, 'feature_names': feature_names, 'target_names': target_names}
    pickle.dump(svm_model, open(svm_model_filename, "wb"))

    # Save the grid search results plot
    plt.tight_layout()
    plt.savefig(grid_search_filename)
